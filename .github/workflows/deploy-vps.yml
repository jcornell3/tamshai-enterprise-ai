# Tamshai Enterprise AI - VPS/Stage Deployment Workflow
#
# This workflow deploys changes to the VPS without manual SSH access.
# It uses SSH keys stored in GitHub Secrets to connect and deploy.
#
# Required Secrets:
#   VPS_HOST               - VPS IP address or hostname
#   VPS_SSH_KEY            - Private SSH key for deployment (raw PEM format)
#   VPS_SSH_USER           - SSH username (usually 'root' or 'tamshai')
#   KEYCLOAK_VPS_ADMIN_PASSWORD - Keycloak admin password for VPS/stage realm management
#
# Optional Secrets (for E2E testing):
#   TEST_USER_PASSWORD         - Password for test-user.journey (E2E test service account)
#   TEST_USER_TOTP_SECRET_RAW_STAGE - Raw TOTP secret for stage (falls back to TEST_USER_TOTP_SECRET_RAW)
#   SLACK_WEBHOOK_URL          - For deployment notifications
#   VAULT_ADDR                 - (Future) Vault address for SSH certificate auth
#
# Triggers:
#   - Push to main branch (auto-deploy)
#   - Manual trigger with options
#   - Release published

name: Deploy to VPS

on:
  push:
    branches:
      - main
    paths:
      # Infrastructure (docker-compose, Dockerfiles, Caddy, Kong, DB init, Vault)
      - 'infrastructure/**'
      # Keycloak realm exports and sync scripts
      - 'keycloak/**'
      # Sample data
      - 'sample-data/**'
      # Shared library (all services depend on this)
      - 'services/shared/**'
      # Web client apps (no individual deploy workflows)
      - 'clients/web/**'
      # Deployment and infra scripts
      - 'scripts/**'
      # This workflow itself
      - '.github/workflows/deploy-vps.yml'

  release:
    types: [published]

  # Note: This workflow does NOT run on pull_request or Dependabot branches
  # because it requires VPS deployment secrets which are not available to forks/PRs

  workflow_dispatch:
    inputs:
      branch:
        description: 'Branch to deploy'
        required: true
        default: 'main'
      build:
        description: 'Rebuild containers'
        required: false
        type: boolean
        default: false
      reseed_data:
        description: 'Re-seed sample data (Finance, Sales, Support)'
        required: false
        type: boolean
        default: false
      force_password_reset:
        description: 'Reset all synced user passwords to STAGE_USER_PASSWORD'
        required: false
        type: boolean
        default: false
      environment:
        description: 'Target environment'
        required: true
        type: choice
        options:
          - staging
          - production
        default: 'staging'

concurrency:
  group: deploy-${{ github.event.inputs.environment || 'staging' }}
  cancel-in-progress: true

env:
  DEPLOY_BRANCH: ${{ github.event.inputs.branch || 'main' }}
  BUILD_FLAG: ${{ github.event.inputs.build && '--build --no-cache' || '--build' }}
  RESEED_DATA: ${{ github.event.inputs.reseed_data || 'false' }}
  ENVIRONMENT: ${{ github.event.inputs.environment || 'staging' }}

# Minimal permissions - deployment uses SSH keys
permissions:
  contents: read
  deployments: write
  packages: none
  statuses: write
  actions: none
  checks: none
  pages: none
  pull-requests: none
  repository-projects: none
  security-events: none

jobs:
  # =============================================================================
  # PRE-DEPLOYMENT CHECKS
  # =============================================================================
  pre-deploy:
    name: Pre-deployment Checks
    runs-on: ubuntu-latest
    permissions:
      contents: read
    outputs:
      should_deploy: ${{ steps.check.outputs.should_deploy }}

    steps:
      - name: Checkout code
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v4

      - name: Check for deployment secrets
        id: check
        run: |
          if [ -z "${{ secrets.VPS_HOST }}" ]; then
            echo "::warning::VPS_HOST secret is not configured - skipping deployment"
            echo "should_deploy=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          if [ -z "${{ secrets.VPS_SSH_KEY }}" ]; then
            echo "::warning::VPS_SSH_KEY secret is not configured - skipping deployment"
            echo "should_deploy=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          echo "should_deploy=true" >> $GITHUB_OUTPUT

      - name: Validate docker-compose.yml
        env:
          # Default values for CI validation only (not used in real deployment)
          COMPOSE_PROJECT_NAME: tamshai-vps
          KEYCLOAK_MODE: start
          TAMSHAI_DB_PASSWORD: ci_test_value
          POSTGRES_PASSWORD: ci_test_value
          KEYCLOAK_DB_PASSWORD: ci_test_value
          MONGODB_PASSWORD: ci_test_value
          REDIS_PASSWORD: ci_test_value
          MINIO_ROOT_USER: ci_test_value
          MINIO_ROOT_PASSWORD: ci_test_value
          KEYCLOAK_ADMIN: admin
          KEYCLOAK_ADMIN_PASSWORD: ci_test_value
          KEYCLOAK_ISSUER: http://localhost:8080/realms/tamshai
          KEYCLOAK_URL: http://localhost:8080
          KC_HOSTNAME: localhost
          VITE_MCP_GATEWAY_URL: http://localhost:${{ vars.DEV_MCP_GATEWAY }}
          VITE_KEYCLOAK_URL: http://localhost:${{ vars.DEV_KEYCLOAK }}
          ELASTIC_PASSWORD: ${{ secrets.ELASTIC_PASSWORD }}
          VAULT_DEV_ROOT_TOKEN: ci_test_value
          MCP_INTERNAL_SECRET: ci_test_value
          MCP_UI_CLIENT_SECRET: ci_test_value
          MCP_GATEWAY_CLIENT_SECRET: ci_test_value
          MCP_HR_SERVICE_CLIENT_SECRET: ci_test_value
          E2E_ADMIN_API_KEY: ci_test_value
          TAMSHAI_APP_PASSWORD: ci_test_value
          # Port Configuration (from GitHub Variables)
          PORT_CADDY_HTTP: ${{ vars.DEV_CADDY_HTTP }}
          PORT_CADDY_HTTPS: ${{ vars.DEV_CADDY_HTTPS }}
          PORT_KEYCLOAK: ${{ vars.DEV_KEYCLOAK }}
          PORT_KONG_PROXY: ${{ vars.DEV_KONG_PROXY }}
          PORT_KONG_ADMIN: ${{ vars.DEV_KONG_ADMIN }}
          PORT_VAULT: ${{ vars.DEV_VAULT }}
          PORT_POSTGRES: ${{ vars.DEV_POSTGRES }}
          PORT_MONGODB: ${{ vars.DEV_MONGODB }}
          PORT_REDIS: ${{ vars.DEV_REDIS }}
          PORT_ELASTICSEARCH: ${{ vars.DEV_ELASTICSEARCH }}
          PORT_MINIO_API: ${{ vars.DEV_MINIO_API }}
          PORT_MINIO_CONSOLE: ${{ vars.DEV_MINIO_CONSOLE }}
          PORT_MCP_GATEWAY: ${{ vars.DEV_MCP_GATEWAY }}
          PORT_MCP_HR: ${{ vars.DEV_MCP_HR }}
          PORT_MCP_FINANCE: ${{ vars.DEV_MCP_FINANCE }}
          PORT_MCP_SALES: ${{ vars.DEV_MCP_SALES }}
          PORT_MCP_SUPPORT: ${{ vars.DEV_MCP_SUPPORT }}
          PORT_MCP_JOURNEY: ${{ vars.DEV_MCP_JOURNEY }}
          PORT_MCP_PAYROLL: ${{ vars.DEV_MCP_PAYROLL }}
          PORT_MCP_TAX: ${{ vars.DEV_MCP_TAX }}
          PORT_MCP_UI: ${{ vars.DEV_MCP_UI }}
          PORT_WEB_PORTAL: ${{ vars.DEV_WEB_PORTAL }}
          PORT_WEB_HR: ${{ vars.DEV_WEB_HR }}
          PORT_WEB_FINANCE: ${{ vars.DEV_WEB_FINANCE }}
          PORT_WEB_SALES: ${{ vars.DEV_WEB_SALES }}
          PORT_WEB_SUPPORT: ${{ vars.DEV_WEB_SUPPORT }}
          PORT_WEB_PAYROLL: ${{ vars.DEV_WEB_PAYROLL }}
          PORT_WEB_TAX: ${{ vars.DEV_WEB_TAX }}
          PORT_WEB_CUSTOMER_SUPPORT: ${{ vars.DEV_WEB_CUSTOMER_SUPPORT }}
          PORT_WEBSITE: ${{ vars.DEV_WEBSITE }}
        run: |
          # Validate docker-compose configuration (uses env vars above for syntax check)
          docker compose -f infrastructure/docker/docker-compose.yml config --quiet

  # =============================================================================
  # BUILD AND TEST
  # =============================================================================
  build-test:
    name: Build and Test
    runs-on: ubuntu-latest
    needs: pre-deploy
    if: needs.pre-deploy.outputs.should_deploy == 'true'
    permissions:
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v4

      - name: Set up Node.js
        uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: services/mcp-gateway/package-lock.json

      - name: Build shared package
        working-directory: services/shared
        run: |
          npm ci
          npm run build

      - name: Install dependencies
        working-directory: services/mcp-gateway
        run: npm ci

      - name: Run type check
        working-directory: services/mcp-gateway
        run: npm run typecheck

      - name: Run tests
        working-directory: services/mcp-gateway
        run: npm test

      - name: Build check
        working-directory: services/mcp-gateway
        run: npm run build

  # =============================================================================
  # DEPLOY TO VPS
  # =============================================================================
  deploy:
    name: Deploy to VPS
    runs-on: ubuntu-latest
    needs: [pre-deploy, build-test]
    if: needs.pre-deploy.outputs.should_deploy == 'true'
    permissions:
      contents: read
      deployments: write
    environment:
      name: ${{ github.event.inputs.environment || 'staging' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v4

      - name: Setup SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.VPS_SSH_KEY }}" > ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519
          # Validate key format
          ssh-keygen -y -f ~/.ssh/id_ed25519 > /dev/null 2>&1 || {
            echo "::error::SSH key format is invalid"
            exit 1
          }
          ssh-keyscan -H ${{ secrets.VPS_HOST }} >> ~/.ssh/known_hosts 2>/dev/null || {
            echo "::warning::Could not scan host keys, continuing anyway"
          }
          echo "SSH key configured"

      - name: Ensure VPS .env has all required variables
        env:
          VPS_HOST: ${{ secrets.VPS_HOST }}
          VPS_USER: ${{ secrets.VPS_SSH_USER || 'root' }}
          # Secrets that may be missing from old VPS .env files
          REDIS_PASSWORD: ${{ secrets.STAGE_REDIS_PASSWORD || 'changeme' }}
          ELASTIC_PASSWORD: ${{ secrets.ELASTIC_PASSWORD }}
          VAULT_DEV_ROOT_TOKEN: ${{ secrets.VAULT_DEV_ROOT_TOKEN_ID || 'dev-root-token' }}
          MCP_INTERNAL_SECRET: ${{ secrets.MCP_INTERNAL_SECRET }}
          MCP_UI_CLIENT_SECRET: ${{ secrets.MCP_UI_CLIENT_SECRET }}
          E2E_ADMIN_API_KEY: ${{ secrets.E2E_ADMIN_API_KEY }}
          TAMSHAI_APP_PASSWORD: ${{ secrets.STAGE_TAMSHAI_APP_PASSWORD }}
          # MCP client secrets (for sync-realm.sh and service authentication)
          MCP_HR_SERVICE_CLIENT_SECRET: ${{ secrets.MCP_HR_SERVICE_CLIENT_SECRET }}
          MCP_GATEWAY_CLIENT_SECRET: ${{ secrets.MCP_GATEWAY_CLIENT_SECRET }}
          # User credential secrets (for realm export substitution and identity-sync)
          TEST_USER_PASSWORD: ${{ secrets.TEST_USER_PASSWORD }}
          TEST_USER_TOTP_SECRET_RAW: ${{ secrets.TEST_USER_TOTP_SECRET_RAW }}
          STAGE_USER_PASSWORD: ${{ secrets.STAGE_USER_PASSWORD }}
        run: |
          SSH_CMD="ssh -o ConnectTimeout=30 -o ServerAliveInterval=15 -o ServerAliveCountMax=40 -i ~/.ssh/id_ed25519 -o IdentitiesOnly=yes $VPS_USER@$VPS_HOST"

          # Build a list of var=value pairs to ensure exist in .env
          # Uses upsert pattern: update if exists, insert if not
          ENSURE_SCRIPT='cd /opt/tamshai && upsert() {
            if grep -q "^$1=" .env 2>/dev/null; then
              sed -i "s|^$1=.*|$1=$2|" .env
            else
              echo "$1=$2" >> .env
            fi
          }'

          # Secret variables (may be missing from original bootstrap)
          # Use upsert to ensure secrets are updated on each deploy (supports rotation)
          ENSURE_SCRIPT="$ENSURE_SCRIPT"'
          upsert REDIS_PASSWORD "'"$REDIS_PASSWORD"'"
          upsert ELASTIC_PASSWORD "'"$ELASTIC_PASSWORD"'"
          upsert VAULT_DEV_ROOT_TOKEN "'"$VAULT_DEV_ROOT_TOKEN"'"
          upsert MCP_INTERNAL_SECRET "'"$MCP_INTERNAL_SECRET"'"
          upsert MCP_UI_CLIENT_SECRET "'"$MCP_UI_CLIENT_SECRET"'"
          upsert MCP_HR_SERVICE_CLIENT_SECRET "'"$MCP_HR_SERVICE_CLIENT_SECRET"'"
          upsert MCP_GATEWAY_CLIENT_SECRET "'"$MCP_GATEWAY_CLIENT_SECRET"'"
          upsert E2E_ADMIN_API_KEY "'"$E2E_ADMIN_API_KEY"'"
          upsert TAMSHAI_APP_PASSWORD "'"$TAMSHAI_APP_PASSWORD"'"
          upsert TEST_USER_PASSWORD "'"$TEST_USER_PASSWORD"'"
          upsert TEST_USER_TOTP_SECRET_RAW "'"$TEST_USER_TOTP_SECRET_RAW"'"
          upsert STAGE_USER_PASSWORD "'"$STAGE_USER_PASSWORD"'"
          upsert KEYCLOAK_ADMIN admin'

          # Port variables use ensure (append-only) since they don't change
          ENSURE_SCRIPT="$ENSURE_SCRIPT"'
          ensure() { grep -q "^$1=" .env 2>/dev/null || echo "$1=$2" >> .env; }'

          # Port variables (sourced from GitHub repository variables)
          ENSURE_SCRIPT="$ENSURE_SCRIPT"'
          ensure PORT_REDIS '"${{ vars.DEV_REDIS }}"'
          ensure PORT_VAULT '"${{ vars.DEV_VAULT }}"'
          ensure PORT_CADDY_HTTP '"${{ vars.DEV_CADDY_HTTP }}"'
          ensure PORT_CADDY_HTTPS '"${{ vars.DEV_CADDY_HTTPS }}"'
          ensure PORT_KEYCLOAK '"${{ vars.DEV_KEYCLOAK }}"'
          ensure PORT_KONG_PROXY '"${{ vars.DEV_KONG_PROXY }}"'
          ensure PORT_KONG_ADMIN '"${{ vars.DEV_KONG_ADMIN }}"'
          ensure PORT_MCP_GATEWAY '"${{ vars.DEV_MCP_GATEWAY }}"'
          ensure PORT_MCP_UI '"${{ vars.DEV_MCP_UI }}"'
          ensure PORT_MCP_HR '"${{ vars.DEV_MCP_HR }}"'
          ensure PORT_MCP_FINANCE '"${{ vars.DEV_MCP_FINANCE }}"'
          ensure PORT_MCP_SALES '"${{ vars.DEV_MCP_SALES }}"'
          ensure PORT_MCP_SUPPORT '"${{ vars.DEV_MCP_SUPPORT }}"'
          ensure PORT_MCP_JOURNEY '"${{ vars.DEV_MCP_JOURNEY }}"'
          ensure PORT_MCP_PAYROLL '"${{ vars.DEV_MCP_PAYROLL }}"'
          ensure PORT_MCP_TAX '"${{ vars.DEV_MCP_TAX }}"'
          ensure PORT_WEB_PORTAL '"${{ vars.DEV_WEB_PORTAL }}"'
          ensure PORT_WEB_HR '"${{ vars.DEV_WEB_HR }}"'
          ensure PORT_WEB_FINANCE '"${{ vars.DEV_WEB_FINANCE }}"'
          ensure PORT_WEB_SALES '"${{ vars.DEV_WEB_SALES }}"'
          ensure PORT_WEB_SUPPORT '"${{ vars.DEV_WEB_SUPPORT }}"'
          ensure PORT_WEB_PAYROLL '"${{ vars.DEV_WEB_PAYROLL }}"'
          ensure PORT_WEB_TAX '"${{ vars.DEV_WEB_TAX }}"'
          ensure PORT_WEB_CUSTOMER_SUPPORT '"${{ vars.DEV_WEB_CUSTOMER_SUPPORT }}"'
          ensure PORT_WEBSITE '"${{ vars.DEV_WEBSITE }}"'
          ensure PORT_POSTGRES '"${{ vars.DEV_POSTGRES }}"'
          ensure PORT_MONGODB '"${{ vars.DEV_MONGODB }}"'
          ensure PORT_ELASTICSEARCH '"${{ vars.DEV_ELASTICSEARCH }}"'
          ensure PORT_MINIO_API '"${{ vars.DEV_MINIO_API }}"'
          ensure PORT_MINIO_CONSOLE '"${{ vars.DEV_MINIO_CONSOLE }}"''

          $SSH_CMD "$ENSURE_SCRIPT"
          echo "VPS .env updated with any missing variables"

      - name: Validate and fix .env
        env:
          VPS_HOST: ${{ secrets.VPS_HOST }}
          VPS_USER: ${{ secrets.VPS_SSH_USER || 'root' }}
        run: |
          echo "=== Validating .env for docker-compose compatibility ==="
          SSH_CMD="ssh -o ConnectTimeout=30 -o ServerAliveInterval=15 -o ServerAliveCountMax=40 -i ~/.ssh/id_ed25519 -o IdentitiesOnly=yes $VPS_USER@$VPS_HOST"

          # Test docker-compose config parsing and fix if needed
          $SSH_CMD << 'VALIDATE_SCRIPT'
          set -e
          cd /opt/tamshai/infrastructure/docker

          # Test if docker-compose can parse the config
          if docker compose --env-file ../../.env config --quiet 2>/dev/null; then
            echo "[OK] .env is valid for docker-compose"
            exit 0
          fi

          echo "[WARN] .env has values that break docker-compose parsing"
          echo "       Fixing malformed password values..."

          cd /opt/tamshai

          # Function to check if a value breaks shell/docker-compose parsing
          # Values with unescaped special chars like ()[]{}|;:<>!? can cause issues
          is_malformed() {
            local val="$1"
            # Check for problematic patterns:
            # - Contains shell metacharacters that aren't properly quoted
            # - Contains multiple = signs (corrupted base64 decode)
            # - Is empty when it shouldn't be
            if echo "$val" | grep -qE '[(){}|;<>]|=[A-Z_]+=' 2>/dev/null; then
              return 0  # true, is malformed
            fi
            return 1  # false, is OK
          }

          # Generate a safe random password (alphanumeric only)
          gen_safe_password() {
            local len="${1:-24}"
            openssl rand -base64 48 | tr -dc 'a-zA-Z0-9' | head -c "$len"
          }

          # List of password variables that may need fixing
          PASSWORD_VARS="REDIS_PASSWORD ELASTIC_PASSWORD POSTGRES_PASSWORD MONGODB_PASSWORD MINIO_ROOT_PASSWORD"

          FIXED_COUNT=0
          for var in $PASSWORD_VARS; do
            current_val=$(grep "^${var}=" .env 2>/dev/null | cut -d= -f2- || echo "")

            if [ -z "$current_val" ] || is_malformed "$current_val"; then
              new_val=$(gen_safe_password 24)
              # Remove old entry and add new one
              sed -i "/^${var}=/d" .env
              echo "${var}=${new_val}" >> .env
              echo "  Fixed: $var"
              FIXED_COUNT=$((FIXED_COUNT + 1))
            fi
          done

          if [ $FIXED_COUNT -gt 0 ]; then
            echo "[OK] Fixed $FIXED_COUNT malformed password(s)"

            # Verify fix worked
            cd infrastructure/docker
            if docker compose --env-file ../../.env config --quiet 2>/dev/null; then
              echo "[OK] .env is now valid for docker-compose"
            else
              echo "[ERROR] .env still has parsing issues after fix"
              echo "        Manual intervention may be required"
              exit 1
            fi
          fi
          VALIDATE_SCRIPT

      - name: Deploy to VPS
        env:
          VPS_HOST: ${{ secrets.VPS_HOST }}
          VPS_USER: ${{ secrets.VPS_SSH_USER || 'root' }}
        run: |
          echo "[DEPLOY] Deploying to $ENVIRONMENT environment..."
          echo "   Host: $VPS_HOST"
          echo "   Branch: $DEPLOY_BRANCH"
          echo "   Build: $BUILD_FLAG"

          ssh -o ConnectTimeout=30 -o ServerAliveInterval=15 -o ServerAliveCountMax=40 -i ~/.ssh/id_ed25519 -o IdentitiesOnly=yes $VPS_USER@$VPS_HOST << 'DEPLOY_SCRIPT'
          set -e
          set +H  # Disable history expansion to handle passwords with special characters like !

          cd /opt/tamshai
          export COMPOSE_PROJECT_NAME=tamshai-vps

          echo "=== Pulling latest code ==="
          git config --global --add safe.directory /opt/tamshai
          git fetch origin
          git checkout ${{ env.DEPLOY_BRANCH }}
          git reset --hard origin/${{ env.DEPLOY_BRANCH }}

          # =========================================================================
          # Fix .env paths for docker-compose running from infrastructure/docker/
          # Old format: ./infrastructure/docker/Caddyfile.stage (root-relative)
          # New format: ./Caddyfile.stage (relative to docker-compose.yml)
          # MUST run BEFORE exporting environment variables
          # =========================================================================
          echo "=== Fixing .env paths for docker-compose directory ==="
          sed -i 's|CADDYFILE=./infrastructure/docker/|CADDYFILE=./|g' .env
          sed -i 's|KONG_CONFIG=./infrastructure/kong/|KONG_CONFIG=../kong/|g' .env
          sed -i 's|KEYCLOAK_REALM=./keycloak/|KEYCLOAK_REALM=../../keycloak/|g' .env
          echo "[OK] .env paths updated for infrastructure/docker/ working directory"

          echo "=== Loading environment ==="
          export $(cat .env | grep -v '^#' | xargs)

          # =========================================================================
          # PHOENIX: Substitute secrets in realm-export-stage.json
          # This ensures users have correct credentials after fresh deploy
          # Placeholders:
          #   __TEST_USER_PASSWORD__ - for test-user.journey (E2E testing)
          #   __TEST_USER_TOTP_SECRET__ - TOTP secret for test-user.journey
          #   __STAGE_USER_PASSWORD__ - for corporate users (eve.thompson, alice.chen, etc.)
          # =========================================================================
          echo "=== Substituting secrets in realm-export-stage.json ==="
          if [ -n "${TEST_USER_PASSWORD}" ]; then
            sed -i "s/__TEST_USER_PASSWORD__/${TEST_USER_PASSWORD}/g" keycloak/realm-export-stage.json
            echo "[OK] TEST_USER_PASSWORD placeholder substituted"
          else
            echo "[WARN] TEST_USER_PASSWORD not set - using placeholder"
          fi

          if [ -n "${TEST_USER_TOTP_SECRET_RAW}" ]; then
            sed -i "s/__TEST_USER_TOTP_SECRET__/${TEST_USER_TOTP_SECRET_RAW}/g" keycloak/realm-export-stage.json
            echo "[OK] TOTP secret placeholder substituted"
          else
            echo "[WARN] TEST_USER_TOTP_SECRET_RAW not set - using placeholder"
          fi

          if [ -n "${STAGE_USER_PASSWORD}" ]; then
            sed -i "s/__STAGE_USER_PASSWORD__/${STAGE_USER_PASSWORD}/g" keycloak/realm-export-stage.json
            echo "[OK] STAGE_USER_PASSWORD placeholder substituted"
          else
            echo "[WARN] STAGE_USER_PASSWORD not set - corporate users will have placeholder passwords"
          fi

          # Use realm-export-stage.json for stage deployment (not dev)
          # Create symlink so docker-compose mounts the correct file
          echo "=== Configuring realm export for stage ==="
          ln -sf ../../../keycloak/realm-export-stage.json infrastructure/docker/realm-export.json
          echo "[OK] Linked realm-export-stage.json for stage deployment"

          echo "=== Building and deploying services ==="
          # Build images on VPS (no container registry configured yet)
          # Change to docker compose directory (paths in docker-compose.yml are relative to compose file)
          cd infrastructure/docker

          # Limit parallel operations to prevent OOM on VPS (8GB RAM).
          # COMPOSE_PARALLEL_LIMIT limits both build and up parallelism.
          # Without this, all 21 images build simultaneously, each running
          # npm ci + tsc, exhausting memory and causing ETIMEDOUT failures.
          export COMPOSE_PARALLEL_LIMIT=3

          COMPOSE="docker compose --env-file ../../.env"
          NOCACHE=""
          if [ "${{ github.event.inputs.build }}" = "true" ]; then
            echo "Force rebuilding with --no-cache..."
            $COMPOSE down
            docker rmi -f web-finance:latest web-sales:latest web-portal:latest 2>/dev/null || true
            NOCACHE="--no-cache"
          fi

          # Build in batches of 3 to prevent OOM on 8GB VPS.
          # Each service runs npm ci + tsc during build; 21 simultaneous
          # builds exhaust memory. Batching keeps peak RAM under control.
          echo "=== Building images in batches of 3 ==="
          BATCH1="mcp-gateway mcp-hr mcp-finance"
          BATCH2="mcp-sales mcp-support mcp-journey"
          BATCH3="mcp-payroll mcp-tax mcp-ui"
          BATCH4="web-portal web-hr web-finance"
          BATCH5="web-sales web-support web-payroll"
          BATCH6="web-tax web-customer-support tamshai-website"
          BATCH7="identity-sync keycloak keycloak-sync"

          for i in 1 2 3 4 5 6 7; do
            eval "BATCH=\$BATCH$i"
            echo "  Building batch $i: $BATCH"
            $COMPOSE build $NOCACHE $BATCH
          done

          echo "=== Stopping stale containers ==="
          # Remove any orphaned or stale containers that may cause "No such container" errors.
          # This happens when previous deployments leave partial state (e.g., container IDs
          # that no longer exist but are still referenced by Docker Compose).
          $COMPOSE down --remove-orphans 2>/dev/null || true

          echo "=== Starting services ==="
          $COMPOSE up -d

          # Always restart Kong to reload declarative config
          # (Docker doesn't restart Kong when only the mounted config file changes)
          echo "=== Restarting Kong to load updated config ==="
          docker restart tamshai-dev-kong
          sleep 5

          echo "=== Cleaning up ==="
          docker image prune -f

          # =========================================================================
          # PHOENIX: Ensure all PostgreSQL databases exist
          # docker-entrypoint-initdb.d scripts only run on first volume creation.
          # If new databases were added after the volume was initialized, they must
          # be created manually with their schemas and sample data.
          # =========================================================================
          echo "=== Ensuring all PostgreSQL databases exist ==="
          EXPECTED_DBS="tamshai_hr tamshai_finance tamshai_payroll tamshai_tax"
          EXISTING_DBS=$(docker exec tamshai-dev-postgres psql -U postgres -t -c "SELECT datname FROM pg_database WHERE datistemplate = false;" | tr -d ' ' | tr '\n' ' ')

          for DB in $EXPECTED_DBS; do
            if echo "$EXISTING_DBS" | grep -qw "$DB"; then
              echo "  [OK] $DB exists"
            else
              echo "  [CREATE] $DB missing - creating database and loading schema..."
              docker exec tamshai-dev-postgres psql -U postgres -c "CREATE DATABASE $DB OWNER tamshai;"
              docker exec tamshai-dev-postgres psql -U postgres -d "$DB" -c "GRANT ALL ON SCHEMA public TO tamshai;"

              # Apply schema and sample data from initdb mount points
              case $DB in
                tamshai_hr)
                  docker exec tamshai-dev-postgres psql -U tamshai -d "$DB" -f /docker-entrypoint-initdb.d/02-hr-data.sql 2>&1 | tail -1
                  docker exec tamshai-dev-postgres psql -U tamshai -d "$DB" -f /docker-entrypoint-initdb.d/08-hr-time-off-schema.sql 2>&1 | tail -1
                  docker exec tamshai-dev-postgres psql -U tamshai -d "$DB" -f /docker-entrypoint-initdb.d/09-hr-time-off-data.sql 2>&1 | tail -1
                  ;;
                tamshai_finance)
                  docker exec tamshai-dev-postgres psql -U tamshai -d "$DB" -f /docker-entrypoint-initdb.d/03-finance-data.sql 2>&1 | tail -1
                  ;;
                tamshai_payroll)
                  docker exec tamshai-dev-postgres psql -U tamshai -d "$DB" -f /docker-entrypoint-initdb.d/04-payroll-schema.sql 2>&1 | tail -1
                  docker exec tamshai-dev-postgres psql -U tamshai -d "$DB" -f /docker-entrypoint-initdb.d/05-payroll-data.sql 2>&1 | tail -1
                  ;;
                tamshai_tax)
                  docker exec tamshai-dev-postgres psql -U tamshai -d "$DB" -f /docker-entrypoint-initdb.d/06-tax-schema.sql 2>&1 | tail -1
                  docker exec tamshai-dev-postgres psql -U tamshai -d "$DB" -f /docker-entrypoint-initdb.d/07-tax-data.sql 2>&1 | tail -1
                  ;;
              esac

              echo "  [OK] $DB created and initialized"
            fi
          done

          # Restart any MCP services that were unhealthy due to missing databases
          for SVC in tamshai-dev-mcp-hr tamshai-dev-mcp-finance tamshai-dev-mcp-payroll tamshai-dev-mcp-tax; do
            STATUS=$(docker inspect --format='{{.State.Health.Status}}' "$SVC" 2>/dev/null || echo "unknown")
            if [ "$STATUS" = "unhealthy" ]; then
              echo "  [RESTART] $SVC was unhealthy - restarting..."
              docker restart "$SVC"
            fi
          done

          echo "=== Waiting for services ==="
          sleep 45

          echo "=== Health check ==="
          curl -sf http://localhost:${{ vars.DEV_MCP_GATEWAY }}/health && echo "[OK] MCP Gateway: healthy" || echo "[WARN] MCP Gateway: still starting..."
          curl -sf http://localhost:8080/auth/health/ready && echo "[OK] Keycloak: healthy" || echo "[WARN] Keycloak: still starting..."

          echo "=== Waiting for Keycloak to be ready ==="
          for i in 1 2 3 4 5; do
            if curl -sf http://localhost:8080/auth/health/ready >/dev/null 2>&1; then
              echo "[OK] Keycloak is ready"
              break
            fi
            echo "Waiting for Keycloak... attempt $i/5"
            sleep 15
          done

          # Re-seed sample data if requested (DROP and RELOAD for clean data)
          # NOTE: Run this BEFORE Keycloak sync to avoid heredoc termination issues
          if [ "${{ env.RESEED_DATA }}" = "true" ]; then
            echo "=== Re-seeding sample data (clean reload) ==="

            echo "  [1/7] Stopping MCP services..."
            docker stop tamshai-dev-mcp-hr tamshai-dev-mcp-finance tamshai-dev-mcp-sales tamshai-dev-mcp-support tamshai-dev-mcp-payroll tamshai-dev-mcp-tax || true

            echo "  [2/7] Reloading HR data (PostgreSQL)..."
            docker exec tamshai-dev-postgres psql -U postgres -c "DROP DATABASE IF EXISTS tamshai_hr;" && \
            docker exec tamshai-dev-postgres psql -U postgres -c "CREATE DATABASE tamshai_hr OWNER tamshai;" && \
            docker exec -i tamshai-dev-postgres psql -U tamshai -d tamshai_hr < sample-data/hr-data.sql && \
              echo "  [OK] HR database dropped and reloaded" || \
              echo "  [ERROR] HR data reload failed"

            echo "  [3/7] Reloading Finance data (PostgreSQL)..."
            docker exec tamshai-dev-postgres psql -U postgres -c "DROP DATABASE IF EXISTS tamshai_finance;" && \
            docker exec tamshai-dev-postgres psql -U postgres -c "CREATE DATABASE tamshai_finance OWNER tamshai;" && \
            docker exec -i tamshai-dev-postgres psql -U tamshai -d tamshai_finance < sample-data/finance-data.sql && \
              echo "  [OK] Finance database dropped and reloaded" || \
              echo "  [ERROR] Finance data reload failed"

            echo "  [4/7] Reloading Payroll data (PostgreSQL)..."
            docker exec tamshai-dev-postgres psql -U postgres -c "DROP DATABASE IF EXISTS tamshai_payroll;" && \
            docker exec tamshai-dev-postgres psql -U postgres -c "CREATE DATABASE tamshai_payroll OWNER tamshai;" && \
            docker exec tamshai-dev-postgres psql -U tamshai -d tamshai_payroll -f /docker-entrypoint-initdb.d/04-payroll-schema.sql && \
            docker exec tamshai-dev-postgres psql -U tamshai -d tamshai_payroll -f /docker-entrypoint-initdb.d/05-payroll-data.sql && \
              echo "  [OK] Payroll database dropped and reloaded" || \
              echo "  [ERROR] Payroll data reload failed"

            echo "  [5/7] Reloading Tax data (PostgreSQL)..."
            docker exec tamshai-dev-postgres psql -U postgres -c "DROP DATABASE IF EXISTS tamshai_tax;" && \
            docker exec tamshai-dev-postgres psql -U postgres -c "CREATE DATABASE tamshai_tax OWNER tamshai;" && \
            docker exec tamshai-dev-postgres psql -U tamshai -d tamshai_tax -f /docker-entrypoint-initdb.d/06-tax-schema.sql && \
            docker exec tamshai-dev-postgres psql -U tamshai -d tamshai_tax -f /docker-entrypoint-initdb.d/07-tax-data.sql && \
              echo "  [OK] Tax database dropped and reloaded" || \
              echo "  [ERROR] Tax data reload failed"

            echo "  [6/7] Reloading Sales data (MongoDB)..."
            # Get MongoDB password from environment
            MONGODB_PASSWORD=$(grep '^MONGODB_PASSWORD=' .env | cut -d= -f2)
            docker exec -i tamshai-dev-mongodb mongosh -u tamshai -p "$MONGODB_PASSWORD" --authenticationDatabase admin < sample-data/sales-data.js && \
              echo "  [OK] Sales data reloaded (MongoDB script handles drop/recreate)" || \
              echo "  [ERROR] Sales data reload failed"

            echo "  [7/7] Reloading Support data (Elasticsearch)..."
            # Delete existing indexes
            docker exec tamshai-dev-elasticsearch curl -X DELETE "http://localhost:9200/support_tickets,knowledge_base" 2>/dev/null || true
            # Bulk load fresh data
            cat sample-data/support-data.ndjson | docker exec -i tamshai-dev-elasticsearch curl -X POST "http://localhost:9200/_bulk" \
              -H "Content-Type: application/x-ndjson" --data-binary @- 2>/dev/null && \
              echo "  [OK] Support indexes deleted and reloaded" || \
              echo "  [ERROR] Support data reload failed"

            echo "=== Restarting MCP services ==="
            docker start tamshai-dev-mcp-hr tamshai-dev-mcp-finance tamshai-dev-mcp-sales tamshai-dev-mcp-support tamshai-dev-mcp-payroll tamshai-dev-mcp-tax
            docker restart tamshai-dev-mcp-gateway
            sleep 10

            echo "=== Verifying data counts ==="
            echo "  HR employees:"
            docker exec tamshai-dev-postgres psql -U tamshai -d tamshai_hr -t -c "SELECT COUNT(*) FROM hr.employees;" || true
            echo "  Finance budgets (FY2025):"
            docker exec tamshai-dev-postgres psql -U tamshai -d tamshai_finance -c "SELECT fiscal_year, COUNT(*) FROM finance.department_budgets GROUP BY fiscal_year ORDER BY fiscal_year;" || true
            echo "  Payroll employees:"
            docker exec tamshai-dev-postgres psql -U tamshai -d tamshai_payroll -t -c "SELECT COUNT(*) FROM payroll.employees;" || true
            echo "  Tax filings:"
            docker exec tamshai-dev-postgres psql -U tamshai -d tamshai_tax -t -c "SELECT COUNT(*) FROM tax.tax_filings;" || true
            echo "  Sales deals:"
            docker exec tamshai-dev-mongodb mongosh -u tamshai -p "$MONGODB_PASSWORD" --authenticationDatabase admin tamshai_sales --quiet --eval "db.deals.countDocuments()" || true
            echo "  Support tickets:"
            docker exec tamshai-dev-elasticsearch curl -s "http://localhost:9200/support_tickets/_count" | grep -o '"count":[0-9]*' || true
            echo "  Knowledge base articles:"
            docker exec tamshai-dev-elasticsearch curl -s "http://localhost:9200/knowledge_base/_count" | grep -o '"count":[0-9]*' || true
          else
            echo "=== Skipping sample data re-seed (use reseed_data=true to enable) ==="
          fi

          # =========================================================================
          # PHOENIX: Ensure HR sample data exists for identity-sync
          # The HR database is created by PostgreSQL init, but sample employees
          # may not exist if this is a fresh deployment. Load if needed.
          # =========================================================================
          echo "=== Ensuring HR sample data exists (Phoenix principle) ==="
          HR_COUNT=$(docker exec tamshai-dev-postgres psql -U tamshai -d tamshai_hr -t -c "SELECT COUNT(*) FROM hr.employees;" 2>/dev/null | tr -d ' ' || echo "0")

          if [ "$HR_COUNT" = "0" ] || [ -z "$HR_COUNT" ]; then
            echo "[INFO] No HR employees found - loading sample data..."
            # Check if hr schema exists, if not load the full HR data file
            if ! docker exec tamshai-dev-postgres psql -U tamshai -d tamshai_hr -c "\\dt hr.*" 2>/dev/null | grep -q employees; then
              echo "[INFO] HR schema not found - initializing from sample-data/hr-data.sql"
              docker exec -i tamshai-dev-postgres psql -U tamshai -d tamshai_hr < /opt/tamshai/sample-data/hr-data.sql && \
                echo "[OK] HR sample data loaded successfully" || \
                echo "[ERROR] Failed to load HR sample data"
            else
              echo "[INFO] HR schema exists but no employees - data may need reseeding"
              echo "[WARN] Run deployment with reseed_data=true to reload HR employees"
            fi
            # Verify again
            HR_COUNT=$(docker exec tamshai-dev-postgres psql -U tamshai -d tamshai_hr -t -c "SELECT COUNT(*) FROM hr.employees;" 2>/dev/null | tr -d ' ' || echo "0")
          fi

          echo "[INFO] HR employees in database: $HR_COUNT"
          if [ "$HR_COUNT" -lt 1 ]; then
            echo "[WARN] No HR employees found - identity-sync may not create any users"
          fi

          echo "=== Syncing Keycloak configuration ==="
          # Copy sync script and library modules, then fix permissions
          # IMPORTANT: Remove old /tmp/lib first to prevent docker cp nesting issue
          # (docker cp creates /tmp/lib/lib if /tmp/lib already exists)
          docker exec -u 0 tamshai-dev-keycloak rm -rf /tmp/lib /tmp/sync-realm.sh 2>/dev/null || true
          docker cp /opt/tamshai/keycloak/scripts/sync-realm.sh tamshai-dev-keycloak:/tmp/sync-realm.sh
          docker cp /opt/tamshai/keycloak/scripts/lib tamshai-dev-keycloak:/tmp/lib
          docker exec -u 0 tamshai-dev-keycloak bash -c '
            sed -i "s/\r$//" /tmp/sync-realm.sh && chmod 755 /tmp/sync-realm.sh
            find /tmp/lib -name "*.sh" -exec sed -i "s/\r$//" {} \; -exec chmod 755 {} \;
          ' || true
          # Run as keycloak user (non-fatal - deployment succeeds even if sync fails)
          # Pass secrets needed by sync-realm.sh client sync functions
          docker exec \
            -e KEYCLOAK_ADMIN_PASSWORD="$KEYCLOAK_ADMIN_PASSWORD" \
            -e MCP_HR_SERVICE_CLIENT_SECRET="$MCP_HR_SERVICE_CLIENT_SECRET" \
            -e MCP_GATEWAY_CLIENT_SECRET="$MCP_GATEWAY_CLIENT_SECRET" \
            -e MCP_UI_CLIENT_SECRET="$MCP_UI_CLIENT_SECRET" \
            -e TEST_USER_PASSWORD="${{ secrets.TEST_USER_PASSWORD }}" \
            tamshai-dev-keycloak /tmp/sync-realm.sh stage || {
              echo "[WARN] Keycloak sync failed - clients may need manual configuration"
              echo "Run: ./keycloak/scripts/docker-sync-realm.sh stage tamshai-dev-keycloak"
            }

          echo "=== Syncing HR users to Keycloak ==="
          # Run identity-sync to provision HR employees as Keycloak users
          # This must run AFTER realm sync to ensure mcp-hr-service client exists
          # Use --build to ensure latest code is used (image may be cached)
          # Use -T to disable TTY allocation (prevents consuming heredoc stdin)
          # PHOENIX: Identity-sync is REQUIRED for stage - fail deployment if it fails
          # Pass environment variables for password rotation (Phoenix: align all user passwords)
          if ! docker compose --env-file ../../.env run -T --rm --build \
            -e ENVIRONMENT=stage \
            -e STAGE_USER_PASSWORD='${{ secrets.STAGE_USER_PASSWORD }}' \
            identity-sync ${{ github.event.inputs.force_password_reset == 'true' && '--force-password-reset' || '' }}; then
            echo "[ERROR] Identity sync FAILED - deployment aborted"
            echo "Check logs: docker compose --env-file ../../.env logs identity-sync"
            echo "This is fatal for stage environment (Phoenix principle: all users must exist)"
            exit 1
          fi

          # PHOENIX: Verify minimum users exist in Keycloak
          echo "=== Verifying user provisioning ==="
          TOKEN=$(curl -sf -X POST "http://localhost/auth/realms/master/protocol/openid-connect/token" \
            -d "client_id=admin-cli" \
            -d "username=admin" \
            -d "password=${KEYCLOAK_ADMIN_PASSWORD}" \
            -d "grant_type=password" | jq -r '.access_token')

          USER_COUNT=$(curl -sf "http://localhost/auth/admin/realms/tamshai-corp/users?briefRepresentation=true" \
            -H "Authorization: Bearer $TOKEN" | jq 'length')

          echo "Users in Keycloak: $USER_COUNT"

          if [ "$USER_COUNT" -lt 2 ]; then
            echo "[ERROR] Expected at least 2 users (test-user.journey + HR employees)"
            echo "Identity-sync may have failed silently"
            exit 1
          fi
          echo "[OK] User provisioning verified ($USER_COUNT users)"

          echo "=== Deployment complete ==="
          DEPLOY_SCRIPT

      # =========================================================================
      # Configure test-user.journey credentials (runs via SSH to use internal URL)
      # See docs/testing/TEST_USER_JOURNEY.md for details
      # =========================================================================
      - name: Configure test-user.journey credentials
        env:
          VPS_HOST: ${{ secrets.VPS_HOST }}
          VPS_USER: ${{ secrets.VPS_SSH_USER || 'root' }}
        run: |
          echo "Configuring test-user.journey credentials via SSH..."

          # Validate required secrets
          if [ -z "${{ secrets.TEST_USER_PASSWORD }}" ]; then
            echo "ERROR: TEST_USER_PASSWORD secret not set"
            echo "See docs/testing/TEST_USER_JOURNEY.md for setup instructions"
            exit 1
          fi

          ssh -o ConnectTimeout=30 -o ServerAliveInterval=15 -o ServerAliveCountMax=40 -i ~/.ssh/id_ed25519 -o IdentitiesOnly=yes $VPS_USER@$VPS_HOST << 'CONFIGURE_USER_SCRIPT'
          set -e
          set +H  # Disable history expansion for passwords with special characters

          # Use direct port (8180) instead of Caddy proxy (80) for admin API
          # Caddy returns 403 on admin endpoints due to reverse proxy configuration
          KEYCLOAK_URL="http://localhost:8180/auth"
          # Read password from VPS .env file (more reliable than GitHub secret after rebuilds)
          KEYCLOAK_ADMIN_PASSWORD=$(grep "^KEYCLOAK_ADMIN_PASSWORD=" /opt/tamshai/.env | cut -d= -f2-)
          TEST_PASSWORD='${{ secrets.TEST_USER_PASSWORD }}'

          if [ -z "$KEYCLOAK_ADMIN_PASSWORD" ]; then
            echo "ERROR: KEYCLOAK_ADMIN_PASSWORD not found in VPS .env"
            exit 1
          fi

          echo "Using Keycloak URL: $KEYCLOAK_URL (internal)"

          # Wait for Keycloak to be ready (up to 60 seconds)
          echo "Waiting for Keycloak to be ready..."
          KEYCLOAK_READY=false
          for i in {1..12}; do
            if curl -sf -o /dev/null "${KEYCLOAK_URL}/realms/master"; then
              echo "[OK] Keycloak is ready"
              KEYCLOAK_READY=true
              break
            fi
            echo "   Attempt $i/12: Keycloak not ready, waiting 5 seconds..."
            sleep 5
          done

          if [ "$KEYCLOAK_READY" = "false" ]; then
            echo "ERROR: Keycloak not ready after 60 seconds"
            exit 1
          fi

          # Get admin token
          echo "Getting Keycloak admin token..."
          TOKEN_RESPONSE=$(curl -s -X POST "${KEYCLOAK_URL}/realms/master/protocol/openid-connect/token" \
            -H "Content-Type: application/x-www-form-urlencoded" \
            -d "username=admin" \
            -d "password=${KEYCLOAK_ADMIN_PASSWORD}" \
            -d "grant_type=password" \
            -d "client_id=admin-cli")

          TOKEN=$(echo "$TOKEN_RESPONSE" | jq -r '.access_token // empty')

          if [ -z "$TOKEN" ]; then
            echo "ERROR: Could not get admin token"
            echo "Response: $TOKEN_RESPONSE"
            exit 1
          fi
          echo "[OK] Admin token obtained"

          # Verify realm exists before user operations
          echo "Verifying tamshai-corp realm exists..."
          REALM_CHECK=$(curl -s -o /dev/null -w "%{http_code}" \
            "${KEYCLOAK_URL}/admin/realms/tamshai-corp" \
            -H "Authorization: Bearer $TOKEN")
          if [ "$REALM_CHECK" != "200" ]; then
            echo "ERROR: tamshai-corp realm not found (HTTP $REALM_CHECK)"
            echo "Keycloak may not have imported the realm export correctly"
            exit 1
          fi
          echo "[OK] tamshai-corp realm exists"

          # Get test-user.journey ID (create if doesn't exist - Phoenix principle)
          USER_ID=$(curl -sf "${KEYCLOAK_URL}/admin/realms/tamshai-corp/users?username=test-user.journey" \
            -H "Authorization: Bearer $TOKEN" | jq -r '.[0].id')

          if [ -z "$USER_ID" ] || [ "$USER_ID" = "null" ]; then
            echo "[WARN] test-user.journey not found in Keycloak - creating..."

            # Create test-user.journey (let Keycloak generate ID - explicit IDs may be forbidden)
            CREATE_RESPONSE=$(curl -s -w "\n%{http_code}" -X POST \
              "${KEYCLOAK_URL}/admin/realms/tamshai-corp/users" \
              -H "Authorization: Bearer $TOKEN" \
              -H "Content-Type: application/json" \
              -d '{
                "username": "test-user.journey",
                "email": "test-user@tamshai.com",
                "firstName": "Test",
                "lastName": "User",
                "enabled": true,
                "emailVerified": true,
                "attributes": {
                  "department": ["Testing"],
                  "employeeId": ["TEST001"],
                  "title": ["Journey Test Account"]
                }
              }')
            CREATE_HTTP=$(echo "$CREATE_RESPONSE" | tail -n1)

            if [ "$CREATE_HTTP" = "201" ] || [ "$CREATE_HTTP" = "409" ]; then
              # 201 = created, 409 = already exists (race condition)
              echo "[OK] test-user.journey created (HTTP $CREATE_HTTP)"
              # Re-fetch user ID
              USER_ID=$(curl -sf "${KEYCLOAK_URL}/admin/realms/tamshai-corp/users?username=test-user.journey" \
                -H "Authorization: Bearer $TOKEN" | jq -r '.[0].id')
            elif [ "$CREATE_HTTP" = "403" ]; then
              echo "ERROR: 403 Forbidden - admin may not have user management permissions"
              echo "Checking admin roles..."
              curl -sf "${KEYCLOAK_URL}/admin/realms/master/users?username=admin" \
                -H "Authorization: Bearer $TOKEN" | jq '.[0].realmRoles // "none"'
              echo "Response body: $(echo "$CREATE_RESPONSE" | head -n-1)"
              exit 1
            else
              echo "ERROR: Failed to create test-user.journey (HTTP $CREATE_HTTP)"
              echo "Response: $(echo "$CREATE_RESPONSE" | head -n-1)"
              exit 1
            fi
          fi

          if [ -z "$USER_ID" ] || [ "$USER_ID" = "null" ]; then
            echo "ERROR: test-user.journey still not found after create attempt"
            exit 1
          fi
          echo "[OK] Found test-user.journey (ID: $USER_ID)"

          # Reset password
          echo "Resetting password for test-user.journey..."
          PASSWORD_JSON=$(jq -n --arg pass "$TEST_PASSWORD" '{"type":"password","value":$pass,"temporary":false}')
          RESET_RESPONSE=$(curl -s -w "\n%{http_code}" -X PUT \
            "${KEYCLOAK_URL}/admin/realms/tamshai-corp/users/${USER_ID}/reset-password" \
            -H "Authorization: Bearer $TOKEN" \
            -H "Content-Type: application/json" \
            -d "$PASSWORD_JSON")
          HTTP_CODE=$(echo "$RESET_RESPONSE" | tail -n1)

          if [ "$HTTP_CODE" = "204" ]; then
            echo "[OK] Password reset successful"
          else
            echo "ERROR: Password reset failed (HTTP $HTTP_CODE)"
            echo "Response: $(echo "$RESET_RESPONSE" | head -n-1)"
            exit 1
          fi

          # Remove existing OTP credentials
          echo "Checking existing credentials..."
          EXISTING_CREDS=$(curl -sf "${KEYCLOAK_URL}/admin/realms/tamshai-corp/users/${USER_ID}/credentials" \
            -H "Authorization: Bearer $TOKEN")
          echo "Existing credentials: $(echo $EXISTING_CREDS | jq -r '[.[].type]')"

          # Delete existing OTP credentials
          for CRED_ID in $(echo $EXISTING_CREDS | jq -r '.[] | select(.type=="otp") | .id'); do
            echo "Deleting OTP credential: $CRED_ID"
            curl -sf -X DELETE "${KEYCLOAK_URL}/admin/realms/tamshai-corp/users/${USER_ID}/credentials/${CRED_ID}" \
              -H "Authorization: Bearer $TOKEN"
          done

          # Create new OTP credential with known secret (matches TEST_USER_TOTP_SECRET for E2E tests)
          TOTP_SECRET_RAW='${{ secrets.TEST_USER_TOTP_SECRET_RAW }}'
          if [ -n "$TOTP_SECRET_RAW" ]; then
            echo "Creating OTP credential with secret: ${TOTP_SECRET_RAW:0:4}****"

            # Build JSON using jq to avoid YAML parsing issues with heredocs
            CREDENTIAL_JSON=$(jq -n \
              --arg secret "$TOTP_SECRET_RAW" \
              '{"type":"otp","userLabel":"GitHub Actions Provisioned","secretData":("{\"value\":\"" + $secret + "\"}") ,"credentialData":"{\"subType\":\"totp\",\"period\":30,\"digits\":6,\"algorithm\":\"HmacSHA1\",\"counter\":0}"}')

            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" -X POST \
              "${KEYCLOAK_URL}/admin/realms/tamshai-corp/users/${USER_ID}/credentials" \
              -H "Authorization: Bearer $TOKEN" \
              -H "Content-Type: application/json" \
              -d "$CREDENTIAL_JSON")

            if [ "$HTTP_CODE" = "201" ] || [ "$HTTP_CODE" = "200" ] || [ "$HTTP_CODE" = "204" ]; then
              echo "[OK] OTP credential created successfully (HTTP $HTTP_CODE)"
            else
              echo "[WARN] OTP credential creation returned HTTP $HTTP_CODE - E2E tests will auto-capture TOTP"
            fi
          else
            echo "[WARN] TEST_USER_TOTP_SECRET_RAW not set - E2E tests will auto-capture TOTP"
          fi

          # Clear required actions
          echo "Clearing required actions..."
          curl -sf -X PUT \
            "${KEYCLOAK_URL}/admin/realms/tamshai-corp/users/${USER_ID}" \
            -H "Authorization: Bearer $TOKEN" \
            -H "Content-Type: application/json" \
            -d '{"requiredActions":[]}' > /dev/null || true

          echo "[OK] test-user.journey configured successfully"

          # Set corporate user passwords from STAGE_USER_PASSWORD (matches dev terraform logic)
          STAGE_PASSWORD='${{ secrets.STAGE_USER_PASSWORD }}'
          if [ -n "$STAGE_PASSWORD" ]; then
            echo ""
            echo "=== Setting corporate user passwords ==="

            # Get all users (excluding test-user.journey)
            ALL_USERS=$(curl -sf "${KEYCLOAK_URL}/admin/realms/tamshai-corp/users?max=500" \
              -H "Authorization: Bearer $TOKEN")

            CORP_COUNT=0
            for row in $(echo "$ALL_USERS" | jq -r '.[] | @base64'); do
              _jq() {
                echo "$row" | base64 -d | jq -r "$1"
              }
              USERNAME=$(_jq '.username')
              USERID=$(_jq '.id')

              # Skip test-user.journey (uses TEST_USER_PASSWORD)
              if [ "$USERNAME" != "test-user.journey" ] && [ -n "$USERID" ]; then
                PASSWORD_JSON=$(jq -n --arg pass "$STAGE_PASSWORD" '{"type":"password","value":$pass,"temporary":false}')
                HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" -X PUT \
                  "${KEYCLOAK_URL}/admin/realms/tamshai-corp/users/${USERID}/reset-password" \
                  -H "Authorization: Bearer $TOKEN" \
                  -H "Content-Type: application/json" \
                  -d "$PASSWORD_JSON")

                if [ "$HTTP_CODE" = "204" ]; then
                  CORP_COUNT=$((CORP_COUNT + 1))
                fi
              fi
            done

            echo "[OK] $CORP_COUNT corporate user passwords set"
          else
            echo "[WARN] STAGE_USER_PASSWORD not set - corporate users have placeholder passwords"
          fi
          CONFIGURE_USER_SCRIPT

      - name: Verify deployment
        run: |
          echo "Verifying external endpoints..."
          DOMAIN="${{ secrets.VPS_DOMAIN || secrets.VPS_HOST }}"

          # Wait for services to be fully ready
          sleep 10

          # Check main endpoints (path-based routing)
          for path in "" "/auth" "/api"; do
            url="https://${DOMAIN}${path}"
            if curl -sf -o /dev/null --max-time 30 "$url"; then
              echo "[OK] $url - OK"
            else
              echo "[WARN] $url - Not reachable (may still be starting)"
            fi
          done

      - name: Notify on success
        if: success()
        continue-on-error: true
        run: |
          if [ -n "$SLACK_WEBHOOK_URL" ]; then
            curl -X POST -H 'Content-type: application/json' \
              --data '{"text":"[SUCCESS] Tamshai deployed successfully to ${{ env.ENVIRONMENT }}\nBranch: ${{ env.DEPLOY_BRANCH }}\nCommit: ${{ github.sha }}"}' \
              "$SLACK_WEBHOOK_URL"
          fi
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Notify on failure
        if: failure()
        continue-on-error: true
        run: |
          if [ -n "$SLACK_WEBHOOK_URL" ]; then
            curl -X POST -H 'Content-type: application/json' \
              --data '{"text":"[FAILED] Tamshai deployment FAILED to ${{ env.ENVIRONMENT }}\nBranch: ${{ env.DEPLOY_BRANCH }}\nSee: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"}' \
              "$SLACK_WEBHOOK_URL"
          fi
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  # =============================================================================
  # POST-DEPLOYMENT
  # =============================================================================
  post-deploy:
    name: Post-deployment Tasks
    runs-on: ubuntu-latest
    needs: deploy
    if: always() && needs.deploy.result == 'success'
    permissions:
      contents: read
      deployments: write

    steps:
      - name: Create deployment record
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v7
        with:
          script: |
            await github.rest.repos.createDeploymentStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              deployment_id: context.payload.deployment?.id || 0,
              state: 'success',
              environment_url: 'https://${{ secrets.VPS_DOMAIN || secrets.VPS_HOST }}',
              description: 'Deployment completed successfully'
            }).catch(() => console.log('Could not create deployment status'));

      - name: Summary
        run: |
          echo "## Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Property | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Environment | ${{ env.ENVIRONMENT }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Branch | ${{ env.DEPLOY_BRANCH }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Commit | ${{ github.sha }} |" >> $GITHUB_STEP_SUMMARY
          echo "| URL | https://${{ secrets.VPS_DOMAIN || secrets.VPS_HOST }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Triggered by | ${{ github.actor }} |" >> $GITHUB_STEP_SUMMARY
